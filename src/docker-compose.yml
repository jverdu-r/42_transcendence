# Removed 'version: '3.8'' as it's obsolete and causes a warning.
# Docker Compose will use the latest version implicitly or based on its own version.

services:
  nginx:
    image: nginx:latest
    container_name: ${PROJECT_NAME}_nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      # Mount the main Nginx configuration from its new location, relative to docker-compose.yml
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      # Remove the conf.d mount for now, as the provided nginx.conf is self-contained.
      # If you later need to include other configurations, you can add this back
      # and ensure your nginx.conf includes directives for /etc/nginx/conf.d/*.conf
      # - ./nginx/conf.d:/etc/nginx/conf.d:ro
      # Mount the frontend's build output directly from the host
      - frontend_dist_volume:/usr/share/nginx/html:ro # Nginx serves the built frontend
    depends_on:
      frontend:
        condition: service_healthy # Ensure frontend build is done and healthy
      backend-auth:
        condition: service_healthy # Nginx might proxy to your authentication service or an API gateway
      backend-game: # Add dependency for backend-game as it's proxied for /ws and /api
        condition: service_healthy

  frontend:
    build:
      # Corrected build context: 'frontend' is a direct sibling of docker-compose.yml within 'src'
      context: ./frontend
    container_name: ${PROJECT_NAME}_frontend
    # This service no longer exposes ports as it's not serving directly.
    # It just builds the assets.
    volumes:
      # Mount a named volume to capture the 'dist' output from the Dockerfile's build stage.
      # The Dockerfile copies /app/dist from the build_stage to /app/dist in the final image.
      # This volume mount ensures that /app/dist inside this container (which contains the built files)
      # is persisted to the named volume on the host.
      - frontend_dist_volume:/app/dist
      # If /home/data/frontend_data is for data used by the frontend at runtime, keep it.
      # Otherwise, if it was related to serving, it can be removed.
      # - /home/data/frontend_data:/app/data
    # This healthcheck now verifies the build output exists in the mounted volume
    healthcheck:
      test: ["CMD-SHELL", "test -f /app/dist/index.html"] # Check if the main index.html exists after build
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s # Give time for the build process to complete

  # --- Message Broker Service ---
  rabbitmq:
    image: rabbitmq:3-management-alpine # Lightweight RabbitMQ with management UI
    container_name: ${PROJECT_NAME}_rabbitmq
    ports:
      - "5672:5672" # AMQP protocol port
      - "15672:15672" # Management UI port (access at http://localhost:15672)
    environment:
      # Removed deprecated RABBITMQ_DEFAULT_USER_FILE and RABBITMQ_DEFAULT_PASS_FILE
      # Pass RABBITMQ_USER and RABBITMQ_PASS directly as environment variables
      # These will be used by docker-compose to interpolate into rabbitmq.conf
      RABBITMQ_USER: ${RABBITMQ_USER}
      RABBITMQ_PASS: ${RABBITMQ_PASS}
    volumes:
      # Mount the config file, which will now contain default_user and default_pass
      - ./rabbitmq/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf:ro
      # Ensure enabled_plugins is a file on your host and contains the necessary plugin list
      - ./rabbitmq/enabled_plugins:/etc/rabbitmq/enabled_plugins:ro # Mount the enabled plugins file
      - ./rabbitmq/entrypoint.sh:/docker-entrypoint.d/rabbitmq_entrypoint.sh:ro # Mount the entrypoint
      - rabbitmq_data:/var/lib/rabbitmq # Volume for RabbitMQ data persistence
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "check_port_connectivity"]
      interval: 10s
      timeout: 5s
      retries: 5
    # Removed explicit 'command: rabbitmq-server' to let the default entrypoint handle startup.

  # --- New Database Service (SQLite) ---
  database:
    build:
      # Corrected build context: 'database' is a direct sibling of docker-compose.yml within 'src'
      context: ./database # Ruta al Dockerfile de la base de datos de tu compañero
    container_name: ${PROJECT_NAME}_database
    volumes:
      - shared_sqlite_data:/app/data # Monta el volumen para la persistencia de SQLite
    # El CMD ya está definido en el Dockerfile para inicializar la DB y mantener el contenedor activo
    # No es necesario exponer puertos a menos que necesites acceder directamente a sqlite desde el host
    healthcheck:
      test: ["CMD-SHELL", "test -f /app/data/transcendance.db"] # Verifica si el archivo de la DB existe
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s # Da tiempo para que la DB se inicialice

  # --- Dedicated SQLite Access Microservice (Processor) ---
  backend-db-access:
    build:
      context: ./backend-db-access # This is the ONLY service that mounts the SQLite volume
    container_name: ${PROJECT_NAME}_backend_db_access
    environment:
      # Asegúrate de que esta URL apunte al archivo de la DB creado por el servicio 'database'
      DATABASE_URL: /app/data/transcendance.db # Ruta al archivo SQLite dentro del contenedor
      RABBITMQ_HOST: rabbitmq # Connect to the RabbitMQ service
      RABBITMQ_USER_FILE: /run/secrets/RABBITMQ_USER
      RABBITMQ_PASS_FILE: /run/secrets/RABBITMQ_PASS
      REQUEST_QUEUE: db_requests # Name of the queue for incoming DB requests
      RESPONSE_QUEUE: db_responses # Name of the queue for outgoing DB responses (optional)
    volumes:
      # Monta el mismo volumen que el servicio 'database' para compartir el archivo SQLite
      - shared_sqlite_data:/app/data
      # Mount the secret files directly into the container for backend-db-access to read
      - ../secrets/RABBITMQ_USER.txt:/run/secrets/RABBITMQ_USER:ro
      - ../secrets/RABBITMQ_PASS.txt:/run/secrets/RABBITMQ_PASS:ro
      - ../secrets/DB_PASSWORD.txt:/run/secrets/DB_PASSWORD:ro # Mount DB_PASSWORD directly
      - ../secrets/API_KEY.txt:/run/secrets/API_KEY:ro # Mount API_KEY directly
    depends_on:
      rabbitmq:
        condition: service_healthy # Wait for RabbitMQ to be ready
      database:
        condition: service_healthy # Espera a que el servicio de la base de datos esté listo
    # Note: This service typically doesn't expose a direct HTTP port if it's purely queue-driven
    # If it has a health endpoint, expose it.
    healthcheck:
      test: ["CMD-SHELL", "pgrep -f 'node db_access_app.js' > /dev/null || exit 1"] # Example: check if process is running
      interval: 10s
      timeout: 5s
      retries: 3

  # --- Other Backend Microservices (Publishers/Consumers) ---
  backend-auth:
    build:
      context: ./backend-auth
    container_name: ${PROJECT_NAME}_backend_auth
    ports:
      - "8081:8081" # Expose auth service port
    environment:
      RABBITMQ_HOST: rabbitmq
      RABBITMQ_USER_FILE: /run/secrets/RABBITMQ_USER
      RABBITMQ_PASS_FILE: /run/secrets/RABBITMQ_PASS
      REQUEST_QUEUE: db_requests
      RESPONSE_QUEUE: db_responses # If auth needs responses
      JWT_SECRET: ${JWT_SECRET:-your-secret-key}
    volumes:
      - ../secrets/RABBITMQ_USER.txt:/run/secrets/RABBITMQ_USER:ro
      - ../secrets/RABBITMQ_PASS.txt:/run/secrets/RABBITMQ_PASS:ro
      - ../secrets/API_KEY.txt:/run/secrets/API_KEY:ro # Mount API_KEY directly
    depends_on:
      rabbitmq:
        condition: service_healthy
      database: # También depende de la base de datos si necesita acceso directo o indirecto
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8081/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s

  backend-game:
    build:
      context: ./backend-game
    container_name: ${PROJECT_NAME}_backend_game
    ports:
      - "8082:8082" # Expose game service port
      - "3000:3000" # Expose WebSocket port for real-time game
    environment:
      RABBITMQ_HOST: rabbitmq
      RABBITMQ_USER_FILE: /run/secrets/RABBITMQ_USER
      RABBITMQ_PASS_FILE: /run/secrets/RABBITMQ_PASS
      REQUEST_QUEUE: db_requests
      RESPONSE_QUEUE: db_responses # If game needs responses
    volumes:
      - ../secrets/RABBITMQ_USER.txt:/run/secrets/RABBITMQ_USER:ro
      - ../secrets/RABBITMQ_PASS.txt:/run/secrets/RABBITMQ_PASS:ro
      - ../secrets/API_KEY.txt:/run/secrets/API_KEY:ro # Mount API_KEY directly
    depends_on:
      rabbitmq:
        condition: service_healthy
      database: # También depende de la base de datos si necesita acceso directo o indirecto
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8082/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s

volumes:
  shared_sqlite_data:
     driver: local
  rabbitmq_data:
    driver: local
  frontend_dist_volume: # Define the new named volume
    driver: local